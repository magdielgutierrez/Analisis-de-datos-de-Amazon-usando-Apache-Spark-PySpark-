{"cells": [{"cell_type": "code", "execution_count": 127, "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark import SparkContext\nspark = SparkSession.builder \\\n  .appName('load_data_amazon dailys') \\\n  .config('spark.jars', 'gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar') \\\n  .getOrCreate()\n\nspark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"}, {"cell_type": "code", "execution_count": 128, "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.types import IntegerType,StringType\nfrom pyspark.sql.functions  import date_sub,current_date,date_trunc,add_months,col\n"}, {"cell_type": "code", "execution_count": 129, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- id: string (nullable = false)\n |-- client_id: string (nullable = false)\n |-- product_id: string (nullable = false)\n |-- cantidad: long (nullable = false)\n |-- precio: double (nullable = false)\n |-- envio_id: string (nullable = true)\n |-- isprime: string (nullable = true)\n |-- fecha_compra: date (nullable = false)\n |-- metodo_pago: string (nullable = true)\n\nlines incoming:  203003\n"}], "source": "#name table compras\ntable_compras = \"amazon_daily_updates.compras \"\n\n#load table\nraw_compras = spark.read \\\n  .format(\"bigquery\") \\\n  .option(\"table\", table_compras) \\\n  .load()\n\nraw_compras.printSchema()\n\n#show incoming lines\nprint(\"lines incoming: \" , raw_compras.count())"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "##########################################################################\n##########################daily jobs ####################################\n#########################################################################"}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": "###########################\n###########################\n# # #filter data previus day\nraw_previus_day= raw_compras.filter(raw_compras.fecha_compra == date_sub(current_date(),1))"}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": "#select columns\nraw_previus_day = raw_previus_day.select('fecha_compra','client_id','precio','product_id','cantidad','isprime')"}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": "raw_previus_day = raw_previus_day.withColumn(\"cantidad\",raw_previus_day.cantidad.cast(IntegerType())) \\\n                                .withColumn(\"isprime\",raw_previus_day.isprime.cast(StringType()))"}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": "#rename columns\nraw_previus_final = raw_previus_day.withColumnRenamed('fecha_compra','purchase_date') \\\n                                .withColumnRenamed('cantidad','product_quantity') \\\n                                .withColumnRenamed('precio','product_price') \\\n                               .withColumnRenamed('isprime','client_is_prime')       "}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "lines incoming:  192\n+-------------+-----------------+-------------+----------+----------------+---------------+\n|purchase_date|        client_id|product_price|product_id|product_quantity|client_is_prime|\n+-------------+-----------------+-------------+----------+----------------+---------------+\n|   2022-03-01|480-146888-22-806|        29.88|B09FCXXGT5|               1|          false|\n|   2022-03-01|310-328278-65-945|         70.0|B01LZZ8UKK|               1|          false|\n|   2022-03-01|323-462812-43-494|         43.7|B08X2K6B1Z|               1|          false|\n|   2022-03-01|323-462812-43-494|        47.99|B098P1M628|               1|          false|\n|   2022-03-01|323-462812-43-494|         8.99|B08ZS9PQ78|               1|          false|\n+-------------+-----------------+-------------+----------+----------------+---------------+\nonly showing top 5 rows\n\n"}], "source": "print(\"lines incoming: \" , raw_previus_day.count())\nraw_previus_final.show(5)\n"}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- fecha_compra: date (nullable = false)\n |-- client_id: string (nullable = false)\n |-- precio: double (nullable = false)\n |-- product_id: string (nullable = false)\n |-- cantidad: integer (nullable = false)\n |-- isprime: string (nullable = true)\n\n"}], "source": "\n#raw_previus_day=raw_previus_day.drop('client_is_prime')\nraw_previus_day.printSchema()"}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [], "source": "######################################################################\n########insert table pr_compras to BigQuery Production ###############\n#####################################################################"}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [], "source": "raw_previus_day.write \\\n  .format(\"bigquery\") \\\n  .option(\"table\",\"becade_mgutierrez.pr_compras\") \\\n  .option(\"temporaryGcsBucket\", \"amazon_magdielgutierrez\") \\\n  .mode('append') \\\n  .save()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [], "source": "#######################################################################"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [], "source": "##########################################################################\n##########################monthly jobs ####################################\n#########################################################################"}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [], "source": "#name table compras\ntable_current_year = \"becade_mgutierrez.pr_compras\"\n\n#load table\nraw_current_year = spark.read \\\n  .format(\"bigquery\") \\\n  .option(\"table\", table_current_year) \\\n  .load()"}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- client_id: string (nullable = true)\n |-- product_price: double (nullable = true)\n |-- product_id: string (nullable = true)\n |-- product_quantity: long (nullable = true)\n |-- client_is_prime: string (nullable = true)\n |-- purchase_date: date (nullable = true)\n\nlines incoming:  2168810\n"}], "source": "#show schema\nraw_current_year.printSchema()\n\n#show incoming lines\nprint(\"lines incoming: \" , raw_current_year.count())"}, {"cell_type": "code", "execution_count": 91, "metadata": {}, "outputs": [], "source": "from pyspark.sql.functions  import year, month,col ,countDistinct,count,add_months"}, {"cell_type": "code", "execution_count": 75, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "lines incoming:  23850\n"}], "source": "#filter data previus day\n#raw_previus_month= raw_previus_month.filter(raw_previus_month.purchase_date == date_sub(current_date(),1))\n\n\n#f1 = raw_previus_month.filter((date_trunc(\"month\", col(\"purchase_date\")) == date_trunc(\"month\", add_months(current_date(), -1))) & (date_trunc(\"year\", col(\"purchase_date\")) == date_trunc(\"year\", current_date())))\ndf_sales_current_year = raw_current_year.filter(  (date_trunc(\"month\", col(\"purchase_date\")) != date_trunc(\"month\", current_date())) &\n                                                (date_trunc(\"year\", col(\"purchase_date\")) == date_trunc(\"year\", current_date())))\n\nprint(\"lines incoming: \" , df_sales_current_year.count())"}, {"cell_type": "code", "execution_count": 76, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------------+-------------+----------+----------------+---------------+-------------+\n|        client_id|product_price|product_id|product_quantity|client_is_prime|purchase_date|\n+-----------------+-------------+----------+----------------+---------------+-------------+\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-01-02|\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-01-05|\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-01-27|\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-01-29|\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-02-08|\n+-----------------+-------------+----------+----------------+---------------+-------------+\nonly showing top 5 rows\n\n"}], "source": "df_sales_current_year.show(5)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 77, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------------+-------------+----------+----------------+---------------+-------------+-----------+----------+\n|        client_id|product_price|product_id|product_quantity|client_is_prime|purchase_date|month_sales|year_sales|\n+-----------------+-------------+----------+----------------+---------------+-------------+-----------+----------+\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-01-02|          1|      2022|\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-01-05|          1|      2022|\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-01-27|          1|      2022|\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-01-29|          1|      2022|\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-02-08|          2|      2022|\n+-----------------+-------------+----------+----------------+---------------+-------------+-----------+----------+\nonly showing top 5 rows\n\nlines source:  23850\n"}], "source": "\ndf_new_sales= df_sales_current_year.withColumn('month_sales',month(df_sales_current_year.purchase_date)) \\\n                .withColumn('year_sales',year(df_sales_current_year.purchase_date))\n\ndf_new_sales.show(5)\n#df_new_sales.printSchema()\nprint(\"lines source: \" , df_new_sales.count())"}, {"cell_type": "code", "execution_count": 78, "metadata": {}, "outputs": [], "source": "#############3TEST\"#######"}, {"cell_type": "code", "execution_count": 79, "metadata": {}, "outputs": [], "source": "# df_new_sales = df_new_sales.select('year_sales','month_sales','product_id') \\\n#         .groupBy('year_sales','month_sales') \\\n#         .agg(count('product_id').alias('product_id')) \\\n#         .sort(['year_sales','month_sales'], ascending=True)\n\n# print(\"lines source: \" , df_new_sales.count())\n# df_new_sales.show(13)"}, {"cell_type": "code", "execution_count": 80, "metadata": {}, "outputs": [], "source": "#######test#########"}, {"cell_type": "code", "execution_count": 81, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+-------------+-----------------+-------------+\n|year_sales|purchase_date|        client_id|total_compras|\n+----------+-------------+-----------------+-------------+\n|      2022|   2022-01-01|801-809134-15-373|            1|\n|      2022|   2022-01-01|323-079732-31-237|            1|\n|      2022|   2022-01-01|435-318881-49-746|            1|\n|      2022|   2022-01-01|602-921290-59-013|            1|\n|      2022|   2022-01-01|480-225626-73-487|            1|\n+----------+-------------+-----------------+-------------+\nonly showing top 5 rows\n\n"}], "source": "###compras por A\u00f1o\ndf_ordenes_year = df_new_sales.select('year_sales','purchase_date','month_sales','client_id') \\\n        .groupBy('year_sales','purchase_date','client_id') \\\n        .agg(countDistinct('client_id').alias('total_compras')) \\\n        .sort(['year_sales', 'purchase_date'], ascending=True)\n\ndf_ordenes_year.show(5)\n# df_ordenes_year.printSchema() "}, {"cell_type": "code", "execution_count": 82, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+-------------+\n|year_sales|total_compras|\n+----------+-------------+\n|      2022|         5025|\n+----------+-------------+\n\n"}], "source": "\n\nsum_ordenes_year = df_ordenes_year.select('year_sales','total_compras') \\\n        .groupBy('year_sales') \\\n        .agg(count('total_compras').alias('total_compras')) \\\n        .sort('year_sales', ascending=True)\nsum_ordenes_year.show()"}, {"cell_type": "code", "execution_count": 83, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+-----------------+------------------+\n|year_sales| venta_total_year| avg_venta_mensual|\n+----------+-----------------+------------------+\n|      2022|2497929.040000331|104.73497023062185|\n+----------+-----------------+------------------+\n\n"}], "source": "from pyspark.sql.functions  import sum,avg\n\ndf_sales = df_new_sales.select('year_sales','month_sales','product_price','client_id') \\\n        .groupBy('year_sales') \\\n        .agg(sum('product_price').alias('venta_total_year'), \\\n             avg('product_price').alias('avg_venta_mensual')) \\\n         .sort('year_sales', ascending=True)\n            \n\n#df_year= df_year.withColumn('venta_total', df_year.venta_total.cast(DecimalType(18, 2)))\n\ndf_sales.show()\n#df_year.printSchema() "}, {"cell_type": "code", "execution_count": 84, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+-----------------+------------------+-------------+\n|year_sales| venta_total_year| avg_venta_mensual|total_compras|\n+----------+-----------------+------------------+-------------+\n|      2022|2497929.040000331|104.73497023062185|         5025|\n+----------+-----------------+------------------+-------------+\n\n"}], "source": "#InnerJoin\nfull_table_year = df_sales.alias('A').join(sum_ordenes_year.alias('B'), col('A.year_sales') == col('B.year_sales'), \"inner\") \n\n#Show first 20 rows\nfull_table_year= full_table_year.select('A.year_sales','A.venta_total_year','A.avg_venta_mensual','B.total_compras') \\\n                 .sort('A.year_sales', ascending=True)\n\nfull_table_year.show()"}, {"cell_type": "code", "execution_count": 85, "metadata": {}, "outputs": [], "source": "full_table_year.write \\\n  .format(\"bigquery\") \\\n  .option(\"table\",\"becade_mgutierrez.pr_compras_anuales\") \\\n  .option(\"temporaryGcsBucket\", \"amazon_magdielgutierrez\") \\\n  .mode('append') \\\n  .save()"}, {"cell_type": "code", "execution_count": 130, "metadata": {}, "outputs": [], "source": "####################MONHT##############"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 154, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "lines incoming:  0\n+---------+-------------+----------+----------------+---------------+-------------+\n|client_id|product_price|product_id|product_quantity|client_is_prime|purchase_date|\n+---------+-------------+----------+----------------+---------------+-------------+\n+---------+-------------+----------+----------------+---------------+-------------+\n\n"}], "source": "#filter data previus day\n#raw_previus_month= raw_previus_month.filter(raw_previus_month.purchase_date == date_sub(current_date(),1))\n\n\ndf_sales_current_month = raw_current_year.filter(((date_trunc(\"month\", col(\"purchase_date\")) == date_trunc(\"month\", add_months(current_date(), -2))) & \n                                                 (date_trunc(\"year\", col(\"purchase_date\")) == date_trunc(\"year\", current_date()))))\n# or\n#                                                  ((date_trunc(\"month\", col(\"purchase_date\")) == date_trunc(\"month\", add_months(current_date(), -2))) & \n#                                                  (date_trunc(\"year\", col(\"purchase_date\")) == '2021')))\n                                               \n\nprint(\"lines incoming: \" , df_sales_current_month.count())\ndf_sales_current_month.show(5)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 148, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------------+-------------+----------+----------------+---------------+-------------+-----------+----------+\n|        client_id|product_price|product_id|product_quantity|client_is_prime|purchase_date|month_sales|year_sales|\n+-----------------+-------------+----------+----------------+---------------+-------------+-----------+----------+\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-01-02|          1|      2022|\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-01-05|          1|      2022|\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-01-27|          1|      2022|\n|831-175061-77-427|       236.99|B00N69D6AS|               1|           true|   2022-01-29|          1|      2022|\n|520-181798-68-069|       236.99|B00N69D6AS|               1|           true|   2022-01-01|          1|      2022|\n+-----------------+-------------+----------+----------------+---------------+-------------+-----------+----------+\nonly showing top 5 rows\n\nlines source:  12050\n"}], "source": "\ndf_new_sales= df_sales_current_month.withColumn('month_sales',month(df_sales_current_year.purchase_date)) \\\n                .withColumn('year_sales',year(df_sales_current_year.purchase_date))\n\ndf_new_sales.show(5)\n#df_new_sales.printSchema()\nprint(\"lines source: \" , df_new_sales.count())"}, {"cell_type": "code", "execution_count": 139, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+-----------+-------------+-----------------+-------------+\n|year_sales|month_sales|purchase_date|        client_id|total_compras|\n+----------+-----------+-------------+-----------------+-------------+\n|      2022|          1|   2022-01-01|602-878245-53-323|            1|\n|      2022|          1|   2022-01-01|435-318881-49-746|            1|\n|      2022|          1|   2022-01-01|702-991490-58-558|            1|\n|      2022|          1|   2022-01-01|801-372658-24-641|            1|\n|      2022|          1|   2022-01-01|801-014440-27-514|            1|\n+----------+-----------+-------------+-----------------+-------------+\nonly showing top 5 rows\n\n"}], "source": "#### datafrem  df_new_sales\n\n###compras por Mes\ndf_ordenes_month = df_new_sales .select('year_sales','purchase_date','month_sales','client_id') \\\n        .groupBy('year_sales','month_sales','purchase_date','client_id') \\\n        .agg(countDistinct('client_id').alias('total_compras')) \\\n        .sort(['year_sales', 'purchase_date'], ascending=True)\n\n#df_year= df_year.withColumn('venta_total', df_year.venta_total.cast(DecimalType(18, 2)))\n\ndf_ordenes_month.show(5)\n# df_ordenes_year.printSchema() "}, {"cell_type": "code", "execution_count": 140, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "lines source:  1\n+----------+-----------+-----------------+\n|year_sales|month_sales|total_compras_mes|\n+----------+-----------+-----------------+\n|      2022|          1|             2575|\n+----------+-----------+-----------------+\n\n"}], "source": "from pyspark.sql.functions  import count\n\nsum_ordenes_month = df_ordenes_month.select('year_sales','month_sales','total_compras') \\\n        .groupBy('year_sales','month_sales') \\\n        .agg(count('total_compras').alias('total_compras_mes')) \\\n        .sort(['year_sales','month_sales'], ascending=True)\n\nprint(\"lines source: \" , sum_ordenes_month.count())\nsum_ordenes_month.show(13)"}, {"cell_type": "code", "execution_count": 141, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "lines source:  1\n+----------+-----------+------------------+\n|year_sales|month_sales|   venta_total_mes|\n+----------+-----------+------------------+\n|      2022|          1|1256540.4599999187|\n+----------+-----------+------------------+\n\n"}], "source": "from pyspark.sql.functions  import sum,avg\n\ndf_month = df_new_sales.select('year_sales','month_sales','product_price') \\\n        .groupBy('year_sales','month_sales') \\\n        .agg(sum('product_price').alias('venta_total_mes')) \\\n        .sort(['year_sales','month_sales'], ascending=True)\n\n#df_year= df_year.withColumn('venta_total', df_year.venta_total.cast(DecimalType(18, 2)))\nprint(\"lines source: \" , df_month.count())\ndf_month.show(13)\n#df_year.printSchema() "}, {"cell_type": "code", "execution_count": 142, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "lines source:  1\n"}], "source": "from pyspark.sql.window import Window\nfrom pyspark.sql.functions import lag\n\ndf_month_raw = df_month.withColumn('venta_total_mes_anterior',lag(df_month['venta_total_mes']).over(Window.orderBy(\"month_sales\",\"year_sales\")))\nprint(\"lines source: \" , df_month_raw.count())"}, {"cell_type": "code", "execution_count": 143, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+-----------+------------------+------------------------+\n|year_sales|month_sales|   venta_total_mes|venta_total_mes_anterior|\n+----------+-----------+------------------+------------------------+\n|      2022|          1|1256540.4599999187|                     0.0|\n+----------+-----------+------------------+------------------------+\n\n"}], "source": "df_month_raw= df_month_raw.na.fill(value=0,subset=[\"venta_total_mes_anterior\"])\ndf_month_raw.show(5)"}, {"cell_type": "code", "execution_count": 110, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "lines source:  1\n+----------+-----------+------------------+------------------------+-----------------+\n|year_sales|month_sales|   venta_total_mes|venta_total_mes_anterior|total_compras_mes|\n+----------+-----------+------------------+------------------------+-----------------+\n|      2022|          1|1256540.4599999187|                     0.0|             2575|\n+----------+-----------+------------------+------------------------+-----------------+\n\n"}], "source": "#InnerJoin\nfull_table_month = df_month_raw.alias('A').join(sum_ordenes_month.alias('B'), \\\n                (col('A.month_sales') == col('B.month_sales')) & (col('A.year_sales') == col('B.year_sales')) , \"inner\") \n\n#Show first 20 rows\nfull_table_month= full_table_month.select('A.year_sales','A.month_sales','A.venta_total_mes','venta_total_mes_anterior','B.total_compras_mes') \\\n              .sort(['month_sales','year_sales'], ascending=True)\n\nprint(\"lines source: \" , full_table_month.count())\nfull_table_month.show(13)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "#"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}